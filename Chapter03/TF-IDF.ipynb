{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "emma = nltk.corpus.gutenberg.sents('austen-emma.txt')\n",
    "\n",
    "emma_sentences = []\n",
    "emma_word_set = []\n",
    "\n",
    "for sentence in emma:\n",
    "    emma_sentences.append([word.lower() for word in sentence if word.isalpha()])\n",
    "    for word in sentence:\n",
    "        if word.isalpha():\n",
    "            emma_word_set.append(word.lower())\n",
    "\n",
    "emma_word_set = set(emma_word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024390243902439025"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def TermFreq(document, word):\n",
    "    doc_length = len(document)\n",
    "    occurances = len([w for w in document if w == word])\n",
    "    return occurances / doc_length\n",
    "\n",
    "TF(emma_sentences[5], 'ago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_DF_dict():\n",
    "    output = {}\n",
    "    for word in emma_word_set:\n",
    "        output[word] = 0\n",
    "        for doc in emma_sentences:\n",
    "            if word in doc:\n",
    "                output[word] += 1\n",
    "    return output\n",
    "        \n",
    "df_dict = build_DF_dict()\n",
    "\n",
    "df_dict['ago']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InverseDocumentFrequency(word):\n",
    "    N = len(emma_sentences)\n",
    "    try:\n",
    "        df = df_dict[word] + 1\n",
    "    except:\n",
    "        df = 1\n",
    "    return np.log(N/df)\n",
    "\n",
    "InverseDocumentFrequency('ago')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ago - 0.13315118517327126\n",
      "indistinct - 0.20152582861001603\n"
     ]
    }
   ],
   "source": [
    "def TFIDF(doc, word):\n",
    "    tf = TF(doc, word)\n",
    "    idf = InverseDocumentFrequency(word)\n",
    "    return tf*idf\n",
    "\n",
    "print('ago - ' + str(TFIDF(emma_sentences[5],'ago')))\n",
    "print('indistinct - ' + str(TFIDF(emma_sentences[5],'indistinct')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGlove(path):\n",
    "    file = open(path,'r')\n",
    "    model = {}\n",
    "    for l in file:\n",
    "        line = l.split()\n",
    "        word = line[0]\n",
    "        value = np.array([float(val) for val in line[1:]])\n",
    "        model[word] = value\n",
    "    return model\n",
    "\n",
    "glove = loadGlove('glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.32575634e-01  3.16596488e-01 -1.80050732e-01 -3.82070951e-01\n",
      "   4.98493527e-01  5.33804805e-01 -5.46517073e-01  9.12476195e-02\n",
      "  -1.31538483e-01 -2.71967805e-02  2.99867317e-02  2.64278024e-02\n",
      "  -2.06519756e-01 -1.54796634e-01  4.28036366e-01 -5.74977317e-02\n",
      "  -2.65928778e-01  1.60373902e-02 -2.84913561e-01 -2.01252268e-01\n",
      "  -5.96390732e-02  5.72458220e-01  2.06195927e-01 -1.54312293e-01\n",
      "   2.52049805e-01 -1.64638200e+00 -3.42686049e-01  1.02592522e-01\n",
      "   1.42848000e-01 -1.09779902e-01  2.89345488e+00  7.36985634e-02\n",
      "  -3.73648780e-03 -2.76292784e-01  1.50580049e-01  9.80399951e-02\n",
      "   2.24408780e-03  2.83664024e-01  3.92979024e-02 -2.98091634e-01\n",
      "  -1.17309171e-01  2.08815776e-01  6.89953902e-03  2.92777244e-02\n",
      "   5.54180122e-02 -2.20519707e-01 -2.82007805e-01 -4.34917439e-01\n",
      "  -9.69051537e-02 -1.67569878e-01]]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "\n",
    "for word in emma_sentences[5]:\n",
    "    embeddings.append(glove[word])\n",
    "\n",
    "mean_embedding = np.mean(embeddings, axis = 0).reshape(1, -1)\n",
    "\n",
    "print(mean_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.03390627  0.04567951 -0.02513047 -0.05553374  0.06523389  0.07031937\n",
      "  -0.06309126  0.02674499 -0.01073998 -0.00509068  0.00518551  0.00818713\n",
      "  -0.01610237 -0.01486281  0.04954961 -0.0107796  -0.05029558  0.00039276\n",
      "  -0.0192399  -0.01344365 -0.01123742  0.08506534  0.02145731 -0.0159164\n",
      "   0.04411737 -0.17889813 -0.04006272  0.01603446  0.02090289 -0.01344211\n",
      "   0.28346797  0.00696015  0.00484046 -0.02637939  0.01537125  0.01611019\n",
      "   0.00316879  0.0324516   0.00829024 -0.04200008 -0.0058922   0.01996137\n",
      "  -0.00305491 -0.00355021  0.01175475 -0.03423196 -0.02943769 -0.06810232\n",
      "  -0.00775695 -0.0181068 ]]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "\n",
    "for word in emma_sentences[5]:\n",
    "    tfidf = TFIDF(emma_sentences[5], word)\n",
    "    embeddings.append(glove[word]* tfidf) \n",
    "    \n",
    "tfidf_weighted_embedding = np.mean(embeddings, axis = 0).reshape(1, -1)\n",
    "\n",
    "print(tfidf_weighted_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98653879]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(mean_embedding, tfidf_weighted_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchNLP",
   "language": "python",
   "name": "pytorchnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
