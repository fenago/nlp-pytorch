{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"How that personage haunted my dreams, I need scarcely tell you. On\n",
    "stormy nights, when the wind shook the four corners of the house and\n",
    "the surf roared along the cove and up the cliffs, I would see him in a\n",
    "thousand forms, and with a thousand diabolical expressions. Now the leg\n",
    "would be cut off at the knee, now at the hip, now he was a monstrous\n",
    "kind of a creature who had never had but the one leg, and that in the\n",
    "middle of his body. To see him leap and run and pursue me over hedge and\n",
    "ditch was the worst of nightmares. And altogether I paid pretty dear for\n",
    "my monthly fourpenny piece, in the shape of these abominable fancies\"\"\"\n",
    "\n",
    "text = text.replace(',','').replace('.','').lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = set(text)\n",
    "corpus_length = len(corpus)\n",
    "\n",
    "word_dict = {}\n",
    "inverse_word_dict = {}\n",
    "\n",
    "for i, word in enumerate(corpus):\n",
    "    word_dict[word] = i\n",
    "    inverse_word_dict[i] = word\n",
    "\n",
    "data = []\n",
    "\n",
    "for i in range(2, len(text) - 2):\n",
    "    sentence = [text[i-2], text[i-1],\n",
    "               text[i+1], text[i+2]]\n",
    "    target = text[i]\n",
    "    data.append((sentence, target))\n",
    "    \n",
    "print(data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_length = 20\n",
    "\n",
    "class CBoW(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, corpus_length, embedding_dim):\n",
    "        super(CBoW, self).__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(corpus_length, embedding_dim)\n",
    "\n",
    "        self.linear1 = nn.Linear(embedding_dim, 64)\n",
    "        self.linear2 = nn.Linear(64, corpus_length)\n",
    "        \n",
    "        self.activation_function1 = nn.ReLU()\n",
    "        self.activation_function2 = nn.LogSoftmax(dim = -1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
    "        out = self.linear1(embeds)\n",
    "        out = self.activation_function1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.activation_function2(out)\n",
    "        return out\n",
    "\n",
    "    def get_word_emdedding(self, word):\n",
    "        word = torch.LongTensor([word_dict[word]])\n",
    "        return self.embeddings(word).view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBoW(corpus_length, embedding_length)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "def make_sentence_vector(sentence, word_dict):\n",
    "    idxs = [word_dict[w] for w in sentence]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "print(make_sentence_vector(['stormy','nights','when','the'], word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    for sentence, target in data:\n",
    "        model.zero_grad()\n",
    "        sentence_vector = make_sentence_vector(sentence, word_dict)  \n",
    "        log_probs = model(sentence_vector)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_dict[target]], dtype=torch.long))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.data\n",
    "    print('Epoch: '+str(epoch)+', Loss: ' + str(epoch_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_result(input, inverse_word_dict):\n",
    "    index = np.argmax(input)\n",
    "    return inverse_word_dict[index]\n",
    "\n",
    "def predict_sentence(sentence):\n",
    "    sentence_split = sentence.replace('.','').lower().split()\n",
    "    sentence_vector = make_sentence_vector(sentence_split, word_dict)\n",
    "    prediction_array = model(sentence_vector).data.numpy()\n",
    "    print('Preceding Words: {}\\n'.format(sentence_split[:2]))\n",
    "    print('Predicted Word: {}\\n'.format(get_predicted_result(prediction_array[0], inverse_word_dict)))\n",
    "    print('Following Words: {}\\n'.format(sentence_split[2:]))\n",
    "\n",
    "predict_sentence('to see leap and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_word_emdedding('leap'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
